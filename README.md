# RAG v3 - Production-Grade Vietnam Labor Law QA System

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/LlamaIndex-0.10.x-green.svg" alt="LlamaIndex">
  <img src="https://img.shields.io/badge/FastAPI-0.109+-red.svg" alt="FastAPI">
  <img src="https://img.shields.io/badge/Chainlit-1.0+-purple.svg" alt="Chainlit">
</p>

## ğŸ“ Project Structure

```
RAG_v3/
â”œâ”€â”€ .env.example                # Environment config template
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ VIETNAM_LABOR_LAW.pdf   # Source document
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest.py               # Offline PDF â†’ Qdrant ingestion
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Pydantic Settings
â”‚   â”œâ”€â”€ main.py                 # FastAPI entrypoint + Phoenix setup
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py           # API endpoints (/chat, /query, /health)
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic request/response models
â”‚   â”‚
â”‚   â””â”€â”€ engine/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ components.py       # LLM, Embedding, Reranker factories
â”‚       â”œâ”€â”€ retriever.py        # HybridRetriever (Vector + BM25 + RRF)
â”‚       â””â”€â”€ chat_engine.py      # SemanticRouter + CondensePlusContextChatEngine
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ app.py                  # Chainlit UI application
    â”œâ”€â”€ .env.example            # Frontend config
    â””â”€â”€ .chainlit/
        â””â”€â”€ config.toml         # Chainlit UI configuration
```

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.11 (conda env)
- Qdrant Cloud account 
- Groq API key 

### 2. Installation

```bash
# Clone or navigate to RAG_v3
cd RAG_v3

# Create virtual environment
conda create -n RAG python=3.11
conda activate RAG

# Install dependencies
pip install -r requirements.txt
```
LÆ°u Ã½ pháº§n cÃ i thÆ° viá»‡n cÃ³  thá»ƒ sáº½ chia ra lÃ m 2 pháº§n Ä‘á»ƒ cÃ i cho Ä‘á»¡ xung Ä‘á»™t
### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your API keys
nano .env  # or use your preferred editor
```

Required environment variables:
```env
GEMINI_API_KEY=your-gemini-api-key
GROQ_API_KEY=your-groq-api-key
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key
```

### 4. Ingest Data

Place your docx `data/..docx`, then run:

```bash
python scripts/ingest.py --pdf data/...docx
```

### 5. Start Backend Server

```bash
# From project root
python -m src.main

# Or with uvicorn directly
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

The API will be available at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### 6. Start Frontend

```bash
# In a new terminal
cd frontend
cp .env.example .env
chainlit run app.py --port 8501
```

Visit http://localhost:8501 to start chatting!

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚     â”‚             â”‚     â”‚           RAG Engine            â”‚
â”‚   Chainlit  â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â”€â–¶â”‚                                â”‚
â”‚   Frontend  â”‚     â”‚   Backend   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”‚             â”‚â—€â”€â”€â”€â”€â”‚  â”‚ Semantic â”‚  â”‚CondensePlusâ”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  Router  â”‚â”€â–¶â”‚ ChatEngine â”‚  â”‚
                                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                        â”‚        â”‚              â”‚        â”‚
                                        â”‚        â–¼              â–¼        â”‚
                                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                                        â”‚  â”‚    Hybrid Retriever      â”‚  â”‚
                                        â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
                                        â”‚  â”‚  â”‚ Vector â”‚ â”‚  BM25  â”‚   â”‚  â”‚
                                        â”‚  â”‚  â”‚ Search â”‚ â”‚ Search â”‚   â”‚  â”‚
                                        â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
                                        â”‚  â”‚         â”‚ RRF â”‚          â”‚  â”‚
                                        â”‚  â”‚         â–¼     â–¼          â”‚  â”‚
                                        â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
                                        â”‚  â”‚    â”‚  Reranker  â”‚        â”‚  â”‚
                                        â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
                                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚                             â”‚
                                        â–¼                             â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  Qdrant  â”‚                 â”‚  Gemini  â”‚
                                  â”‚  Cloud   â”‚                 â”‚   LLM    â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Observability (Phoenix)

Start Arize Phoenix for tracing:

```bash
# Install Phoenix
pip install arize-phoenix

# Start Phoenix server
phoenix serve

# Phoenix UI: http://localhost:6006
```

Configure in `.env`:
```env
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6006/v1/traces
ENABLE_TRACING=true
```

## ğŸ”§ Configuration Reference

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_PROVIDER` | `groq` | LLM provider (gemini/openai/groq) |
| `EMBEDDING_MODEL` | `bkai-foundation-models/vietnamese-bi-encoder` | Vietnamese embedding |
| `RERANKER_MODEL` | `BAAI/bge-reranker-v2-m3` | Reranker model |
| `VECTOR_TOP_K` | `20` | Vector search results |
| `BM25_TOP_K` | `20` | BM25 search results |
| `RERANKER_TOP_N` | `5` | Final reranked results |
| `RRF_K` | `60` | RRF fusion constant |
